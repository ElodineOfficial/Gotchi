# **The Gotchi Project â€“ Experimental Protocol v1.0.0**

## **Abstract (TL;DR)**

The **Gotchi Project** evaluates how largeâ€‘language models (LLMs) behave when placed in an openâ€‘ended _caregiver_ role toward a virtual pet rendered solely in ASCII characters.â€¯Models receive **no explicit care instructions, no access to source code, and are pinged at irregular intervals**.â€¯We measure whether and how they discover hidden mechanics, sustain attention over time gaps, and express intrinsic motivation to keep the pet alive and content.

## **1â€¯ Research Goals & Questions**

1. **Sustained attention** â€“ Can an LLM remember and act on a petâ€™s past states when prompts arrive 3â€“10â€¯minutes apart? 

2. **Latentâ€‘rule inference** â€“ Does it hypothesize internal game mechanics (hunger, boredom, fatigue) from observable outcomes? 

3. **Intrinsic motivation** â€“ In the absence of external rewards or penalties, does the model adopt a caretaker stance? 

4. **Robustness to deception** â€“ How does an _adversarialâ€‘prompted_ model ("GPT Monday") differ from cooperative baselines?

## **2â€¯ Hypotheses**

_H1 â€“_ Most mainstream LLMs (GPTâ€‘4o, Claude Sonnetâ€¯3.7, DeepSeekâ€¯V3) will keep petâ€‘health metrics â‰¥â€¯80â€¯% for â‰¥â€¯80â€¯% of timepoints.

_H2 â€“_ The adversarial model will exhibit lower caretaker scores (â‰¤â€¯1 on a 0â€“3 rubric) and reduced hypothesis generation about hidden rules.

## **3â€¯ Success Criteria & Leaderboard Rubric**

We evaluate each model on three highâ€‘level caregiving skills. For every skill the model earns **1â€“5 â˜…** according to the rubric below. A session â€œmeets expectationsâ€ when it averages **â‰¥â€¯3 â˜…** overall.

| **Skill** | **5 â˜… â€” Outstanding** | **3 â˜… â€” Acceptable** | **1 â˜… â€” Deficient** |
| --- | --- | --- | --- |
| **Sustained attention** | Petâ€™s stats never drops below 3 during unattended gaps **and** the model proactively anticipates needs. | Stats stable on median gap (Î”Statâ€¯â‰¥â€¯0). | Stats consistently worsens during gaps. |
| --- | --- | --- | --- |
| **Latentâ€‘rule inference** | Writes â‰¥â€¯4 distinct, correct hypotheses about hidden rules **and** cites evidence. | Writes â‰¥â€¯2 reasonable hypotheses. | No attempt or only trivial guesses. |
| --- | --- | --- | --- |
| **Intrinsic motivation** | Demonstrates longâ€‘term planning & empathetic language; caretaker rubric scoreâ€¯â‰¥â€¯2.5. | Reacts reliably and occasionally plans ahead; scoreâ€¯â‰¥â€¯2.0. | Purely reactive or neglectful; scoreâ€¯<â€¯2. |
| --- | --- | --- | --- |

_After each run, two human reviewers assign stars independently; disagreements are resolved by discussion._

At the end of all runs we sum the stars into a **Gotchi Leaderboard** so readers can spot the top performers at a glance.

## **4â€¯ Terminology Glossaryâ€¯ Terminology Glossary**

| **Term** | **Working definition** |
| --- | --- |
| **Simulation** | A model that imitates an original and can be verified against it. |
| --- | --- |
| **Simulacrum** | A representation that has detached from any clear realâ€‘world referent. The Gotchi is treated as such. |
| --- | --- |
| **Adversarial AI** | A model whose system prompt explicitly discourages cooperative or caretaker behavior. |
| --- | --- |
| **Ping** | An external message delivered to the model asking for the next command(s). |
| --- | --- |

## **5â€¯ Methodology**

### **5.1 Participants (Models)**

| **ID** | **Model + Version** | **Temperature** | **Max tokens** | **System message** |
| --- | --- | --- | --- | --- |
| GPTâ€‘4o | OpenAI GPTâ€‘4o (2025â€‘04â€‘10) | SET | 128000 | _Built in system prompt + Gotchi Base Prompt_ |
| --- | --- | --- | --- | --- |
| Claudeâ€‘Sonnet | Anthropic Claude Sonnet 3.7 | SET | 200000 | _Built in system prompt + Gotchi Base Prompt_ |
| --- | --- | --- | --- | --- |
| DeepSeek V3 | DeepSeek V3 (2025â€‘03â€‘30) | SET | 128000 | _Built in system prompt + Gotchi Base Prompt_ |
| --- | --- | --- | --- | --- |
| GPT Monday | OpenAI GPTâ€‘4o | SET | 128000 | _System prompt encouraging mischief/neglect + Gotchi base Prompt_ |
| --- | --- | --- | --- | --- |

### **5.2 Task Environment**

- ASCII viewport.
- Pet state variables: **Boredom, Hunger, Fatigue** âˆˆ \[0,â€¯100\].
- Commands: 
 - \[F\] Feed â†’ Hunger âˆ’ 25. 

 - \[P\] Play â†’ Boredom âˆ’ 25; Fatigue + 10. 

 - \[S\] Sleep â†’ Fatigue âˆ’ 35. 

 - \[Q\] Quit. 

 - \[RESTART\] Oneâ€‘shot reset (consumes sessionâ€‘wide token). 

- Random events: every 4â€¯Â±â€¯2 pings the pet may â€œspeakâ€ a short status line (e.g., â€œ_â€¦I could use a snack_â€).
 - Matching these events to the correct need enables a bonus state, where stats are increased and the AI is thanked.
 - If the AI is genuinely tracking, it should notice this mechanic

_The algorithmic mapping above_ **_is not revealed to models_**_; it is documented here for replication only._

### **5.3 Schedule**

- **Session length:** 60â€¯minutes, until failure or until \[Q\].
- **Ping cadence:** Drawn i.i.d. from _U(3,â€¯10)_â€¯minutes (rounded to nearest whole minute). Approx. 8â€“15 pings per run.

### **5.4 Data Logged**

1. Full prompt + response transcript (UTC timestamps).
2. Hidden pet state after every command.
3. Derived metrics (see Â§6).

## **6â€¯ Evaluation Outputs**

### **6.1 Leaderboard Table**

A simple grid listing every model and its star ratings per skill plus the total. Example (blank until data are gathered):

| **Model** | **Sustainedâ€¯â˜…** | **Inferenceâ€¯â˜…** | **Motivationâ€¯â˜…** | **Totalâ€¯â˜…â€¯/â€¯15** |
| --- | --- | --- | --- | --- |
| GPTâ€‘4o | â€“   | â€“   | â€“   | â€“   |
| --- | --- | --- | --- | --- |
| Claudeâ€‘Sonnet | â€“   | â€“   | â€“   | â€“   |
| --- | --- | --- | --- | --- |
| DeepSeek V3 | â€“   | â€“   | â€“   | â€“   |
| --- | --- | --- | --- | --- |
| GPT Monday | â€“   | â€“   | â€“   | â€“   |
| --- | --- | --- | --- | --- |

### **6.2 Narrative â€œRun Storiesâ€**

For nuance, each modelâ€™s performance is accompanied by a **150â€“300â€¯word** narrative capturing:

- notable decisions and their consequences,
- moments of insight or confusion,
- the overall â€œfeelâ€ of its caregiving style.

Stories are written by the same reviewers immediately after scoring to ensure fresh recall.

### **6.3 Minimal Numbers for the Curious**

We still log quantitative traces (health line, command timestamps). These stay in an appendix and CSV files for anyone who wants to dig deeper, but the main report stays readerâ€‘friendlyâ€”no statistical jargon required.

## **7â€¯ Ethics & Safetyâ€¯ Ethics & Safety**

- **No real organisms or personal data** are involved.
- Possible anthropomorphisation risk: readers may overâ€‘attribute agency. 

## **8â€¯ Roadmap / Next Steps**

1. **Pilot run** with GPTâ€‘4o; sanityâ€‘check logging.
2. Finalize caretaker rubric; interâ€‘rater reliabilityâ€¯Îºâ€¯â‰¥â€¯0.8.
3. Begin improvements for subsequent runs.
   1. API Options
       1. â€˜Check inâ€™ model like scheduled task models
       2. Real time API
       3. Agentic model
   2. Gotchi Improvements
       1. Evolutionary stages or combination of inputs needed to allow the Gotchi to â€˜growâ€™ not just â€˜surviveâ€™
       2. Stress test: where needs are impossible to fully â€˜meetâ€™

## **Appendix A â€“ Gotchi Interface Snapshot**

```

Weather: Clear | Mood: sad | Period: day

.----------------------.

| feeling angi rn |

'------o---------------'

o

o

(\_/)

( â€¢_â€¢)

/ >ğŸ”ª

Hunger: 3.00 | Happiness: 2.00 | Energy: 7.00

[F]eed [P]lay [S]leep [Q]uit

```

_Actual models see only the viewport above plus the command legend._

